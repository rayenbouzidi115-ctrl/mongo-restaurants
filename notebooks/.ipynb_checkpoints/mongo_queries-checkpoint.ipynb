{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462dff05",
   "metadata": {},
   "source": [
    "# NYC Restaurants — PyMongo CRUD\n",
    "Run cells top-to-bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32874f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install pymongo pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d746ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to mongodb://mongo:27017\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import json, os\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "MONGO_URI = \"mongodb://mongo:27017\"\n",
    "DB_NAME = \"nyc\"\n",
    "COLL_NAME = \"restaurants\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "coll = db[COLL_NAME]\n",
    "print(\"Connected to\", MONGO_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30992f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 544)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coll\u001b[38;5;241m.\u001b[39mestimated_document_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrades\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 544)"
     ]
    }
   ],
   "source": [
    "import pathlib, json\n",
    "from datetime import datetime\n",
    "\n",
    "data_path = pathlib.Path(\"/home/jovyan/work/data/restaurants.json\")  # ou restaurants.json\n",
    "\n",
    "def load_docs_flex(path: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Charge soit un JSON array:  [ {...}, {...} ]\n",
    "    soit du NDJSON (JSON Lines): {...}\\n{...}\\n...\n",
    "    Retourne une liste de dicts.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read().strip()\n",
    "    if not txt:\n",
    "        return []\n",
    "    # JSON array ?\n",
    "    if txt[0] == \"[\":\n",
    "        docs = json.loads(txt)\n",
    "    else:\n",
    "        # NDJSON: une ligne = un document\n",
    "        docs = []\n",
    "        for i, line in enumerate(txt.splitlines(), 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                docs.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Ligne {i} invalide (pas un JSON): {e}\")\n",
    "    return docs\n",
    "\n",
    "if coll.estimated_document_count() == 0:\n",
    "    docs = load_docs_flex(data_path)\n",
    "\n",
    "    # Normaliser les dates des grades si présentes (string -> datetime)\n",
    "    for d in docs:\n",
    "        for g in d.get(\"grades\", []):\n",
    "            if isinstance(g.get(\"date\"), str):\n",
    "                try:\n",
    "                    g[\"date\"] = datetime.fromisoformat(g[\"date\"])\n",
    "                except Exception:\n",
    "                    # si le format n'est pas ISO, on ignore: Mongo acceptera la string\n",
    "                    pass\n",
    "\n",
    "    if not docs:\n",
    "        print(\"Aucun document chargé (fichier vide ?)\")\n",
    "    else:\n",
    "        res = coll.insert_many(docs)\n",
    "        print(f\"✅ Inserted {len(res.inserted_ids)} documents from {data_path.name}\")\n",
    "else:\n",
    "    print(\"Collection already has data:\", coll.estimated_document_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e828124",
   "metadata": {},
   "source": [
    "## CREATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_restaurant = {\n",
    "    \"name\": \"Rayen Test Kitchen\",\n",
    "    \"borough\": \"Brooklyn\",\n",
    "    \"cuisine\": \"Bakery\",\n",
    "    \"grades\": [{\"date\": datetime(2024, 1, 5), \"grade\": \"A\"}],\n",
    "    \"address\": {\"building\": \"777\", \"street\": \"Flatbush Ave\", \"zipcode\": \"11226\"}\n",
    "}\n",
    "insert_result = coll.insert_one(new_restaurant)\n",
    "print(\"Inserted _id:\", insert_result.inserted_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d2614",
   "metadata": {},
   "source": [
    "## READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = coll.count_documents({})\n",
    "print(\"Total restaurants:\", total)\n",
    "\n",
    "print(\"\\nBronx restaurants (preview):\")\n",
    "for r in coll.find({\"borough\": \"Bronx\"}, {\"_id\": 0, \"name\": 1, \"borough\": 1}):\n",
    "    print(\"-\", r)\n",
    "\n",
    "print(\"\\nBakery with grade A (preview):\")\n",
    "for r in coll.find({\"cuisine\": \"Bakery\", \"grades.grade\": \"A\"}, {\"_id\": 0, \"name\": 1, \"grades.$\": 1}).limit(20):\n",
    "    print(\"-\", r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c90933",
   "metadata": {},
   "source": [
    "## UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_res = coll.update_one(\n",
    "    {\"name\": \"Morris Park Bake Shop\", \"grades.0\": {\"$exists\": True}},\n",
    "    {\"$set\": {\"grades.0.grade\": \"A+\"}}\n",
    ")\n",
    "print(\"Matched:\", update_res.matched_count, \"| Modified:\", update_res.modified_count)\n",
    "pprint(coll.find_one({\"name\": \"Morris Park Bake Shop\"}, {\"_id\": 0, \"name\": 1, \"grades\": 1}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d5ca0",
   "metadata": {},
   "source": [
    "## DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_res = coll.delete_many({\"grades.grade\": \"C\"})\n",
    "print(\"Deleted grade C:\", delete_res.deleted_count)\n",
    "print(\"Remaining grade C:\", coll.count_documents({\"grades.grade\": \"C\"}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
